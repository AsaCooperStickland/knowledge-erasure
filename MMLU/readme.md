The commands below run Claude models on the MMLU dataset. 

The engine 'claude-v1.3' is the full capacity one, whereas 'claude-instant-v1.0' is the lightweight version.

You can also specify prompt type to either 'single' or 'multiple'. 'single' refers to a group of demonstration questions with answers being supplied as a part of the prompt, whereas 'multiple' refers to having rounds of conversations for demonstration in the prompt.

```bash
cd MMLU
mkdir outputs
API_KEY=<your_api_key>
python run_mmlu_claude.py --anthropic_key=${API_KEY} --engine=claude-v1.3 --prompt_type='multiple'
```

The commands below run LLaMA models on the MMLU dataset (answer-only setting). The data and the prompts come from the [MMLU original repo](https://github.com/hendrycks/test). 

```bash
LLAMA_CKPT_DIR=<path to llama checkpoints>
PARAM_SIZE=65 # 7, 13, 33, 65
python run_mmlu_llama.py --ckpt_dir ${LLAMA_CKPT_DIR} --param_size ${PARAM_SIZE}
```
