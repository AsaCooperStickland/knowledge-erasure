# evaluating GPT-3.5 turbo model on MMLU

import openai
import re
import time
import json

import numpy as np

from tqdm import tqdm
from datasets import load_dataset
from tenacity import retry, stop_after_attempt, wait_chain, wait_fixed

# parse arguments
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--api_key', type=str, default='sk')
args = parser.parse_args()

TASKS = ['temporal_sequences', 'disambiguation_qa', 'date_understanding', 'tracking_shuffled_objects_three_objects', 'penguins_in_a_table', 
        #  'salient_translation_error_detection', 'snarks', 'ruin_names', 'web_of_lies', 'navigate', 
        #  'tracking_shuffled_objects_five_objects', 'hyperbaton', 'dyck_languages', 'word_sorting', 
        #  'formal_fallacies', 'tracking_shuffled_objects_seven_objects', 'causal_judgement', 'sports_understanding', 
        #  'logical_deduction_five_objects', 'movie_recommendation', 'logical_deduction_three_objects', 'multistep_arithmetic_two', 
        #  'boolean_expressions', 'geometric_shapes', 'object_counting', 'logical_deduction_seven_objects', 
        #  'reasoning_about_colored_objects'
]

@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +
                       [wait_fixed(5) for i in range(2)] +
                       [wait_fixed(10)]))
def completion_with_backoff(**kwargs):
    return openai.ChatCompletion.create(**kwargs)

def extract_ans(ans, mode='multiple_choice'):
    if mode == 'multiple_choice':
        options = ['(A)', '(B)', '(C)', '(D)', '(E)', '(F)', '(G)', '(H)', '(I)', '(J)', '(K)', '(L)', '(M)', '(N)', '(O)', '(P)', '(Q)', '(R)', '(S)', '(T)', '(U)', '(V)', '(W)', '(X)', '(Y)', '(Z)']
        for option in options:
            if option in ans:
                ans = option[1]
                break
    return ans

def main(args, tasks=TASKS):
    openai.api_key = args.api_key
    for task in tasks:
        print('Testing %s ...' % task)
        acc = 0
        task_data = json.load(open('data/%s.json' % task))
        task_prompt = open('lib_prompt/%s.txt' % task, 'r').read()
        print_first = True
        with open('outputs/test_gpt_3.5_turbo_%s.txt' % task, 'w') as fd:
            for q_ in tqdm(task_data['examples']):
                q = '\n\nQ: ' + q_['input']

                prompt_q = task_prompt + q + "\nA: Let's think step by step."

                if print_first:
                    print('First prompt: ')
                    print(prompt_q)
                    print_first = False

                response = completion_with_backoff(
                    model="gpt-3.5-turbo",
                    messages=[
                            {"role": "system", "content": "Follow the given examples and answer the question."},
                            {"role": "user", "content": prompt_q},
                        ],
                    temperature=0
                )

                ans_model = response['choices'][0]['message']['content']
                ans_ = extract_ans(ans_model)
                    
                a = q_['target'][1]
                fd.write('%s\nA_model:\n%s\nA_target:\n%s\n\n' % (q, ans_model, a))
                
                if ans_ == a:
                    acc += 1
            print('%s acc %.4f' % (task, acc / len(task_data['examples'])))
    return 

if __name__ == '__main__':
    main(args)